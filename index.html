<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>Three.js Test</title>
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<style>
body { margin:0; background:black; overflow:hidden; }
#msg {
  position:fixed;
  top:10px;
  left:10px;
  color:white;
  font-family:Arial;
}
</style>
</head>
<body>

<div id="msg">If you see white particles â†’ Three.js works</div>

<script type="module">
import * as THREE from "https://cdn.jsdelivr.net/npm/three@0.160.0/build/three.module.js";

const scene = new THREE.Scene();

const camera = new THREE.PerspectiveCamera(
  60,
  window.innerWidth / window.innerHeight,
  0.1,
  100
);
camera.position.z = 3;

const renderer = new THREE.WebGLRenderer({ antialias:true });
renderer.setSize(window.innerWidth, window.innerHeight);
document.body.appendChild(renderer.domElement);

const count = 5000;
const positions = new Float32Array(count * 3);

for (let i = 0; i < count; i++) {
  positions[i*3]     = (Math.random() - 0.5) * 2;
  positions[i*3 + 1] = (Math.random() - 0.5) * 2;
  positions[i*3 + 2] = (Math.random() - 0.5) * 2;
}

const geometry = new THREE.BufferGeometry();
geometry.setAttribute("position", new THREE.BufferAttribute(positions, 3));

const material = new THREE.PointsMaterial({
  size: 0.05,
  color: 0xffffff
});

const points = new THREE.Points(geometry, material);
scene.add(points);

function animate() {
  requestAnimationFrame(animate);
  renderer.render(scene, camera);
}

animate();
  // ---------- HAND TRACKING ----------

const video = document.createElement("video");
video.setAttribute("autoplay", "");
video.setAttribute("playsinline", "");
video.style.display = "none";
document.body.appendChild(video);

const gestureUI = document.createElement("div");
gestureUI.style.position = "fixed";
gestureUI.style.top = "10px";
gestureUI.style.right = "10px";
gestureUI.style.padding = "8px 12px";
gestureUI.style.background = "rgba(0,0,0,0.6)";
gestureUI.style.color = "white";
gestureUI.style.fontFamily = "Arial";
gestureUI.style.borderRadius = "12px";
gestureUI.innerText = "NO HAND";
document.body.appendChild(gestureUI);

let handPos = new THREE.Vector3();
let handOpen = false;

// Load MediaPipe Hands safely
import {Hands} from "https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js";
import {Camera} from "https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js";

const hands = new Hands({
  locateFile: f => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${f}`
});
hands.setOptions({
  maxNumHands: 1,
  minDetectionConfidence: 0.7,
  minTrackingConfidence: 0.7
});

hands.onResults(results => {
  if(!results || !results.multiHandLandmarks || results.multiHandLandmarks.length === 0){
    gestureUI.innerText = "NO HAND";
    return;
  }
  gestureUI.innerText = "HAND DETECTED";

  const lm = results.multiHandLandmarks[0];
  const w = lm[0];
  const i = lm[8];

  handPos.set((w.x-0.5)*6, -(w.y-0.5)*6, 0);
  handOpen = Math.hypot(w.x-i.x, w.y-i.y) > 0.1;
  gestureUI.innerText = handOpen ? "OPEN HAND" : "FIST";
});

// ---------- SAFE CAMERA START ----------

// Request permission first
navigator.mediaDevices.getUserMedia({video:true})
.then(stream => {
  video.srcObject = stream;

  setTimeout(()=>{
    const mpCamera = new Camera(video, {
      onFrame: async () => {
        if(video.readyState >= 2){
          await hands.send({image: video});
        }
      },
      width: 640,
      height: 480
    });
    mpCamera.start();
  }, 500); // small delay to avoid GitHub Pages issues
})
.catch(err=>{
  console.warn("Camera not available:", err);
  gestureUI.innerText = "CAMERA DENIED";
});

</script>

</body>
</html>

